Core Technologies
Storage
    * local fs
    * S3-compatible buckets
    * Rasters
        * Zarr data format
        * Icechunk, tensor storage engine
        * VirtualiZarr for virtual datasets
Open File Formats for Data Lakehouse
    * Parquet
        * sources for Lakehouse tables
        * exported raster virtual datasets
    * COG and GeoTIFF for rasters
        * source for Zarr and Icechunk stores
Data Lakehouse Catalog and metadata handling
    * Apache Iceberg, open table format 
    * DuckLake, an open Catalog format that offers a pure SQL approach
    * STAC for metadata and asset discovery
    * H3 spatial indexing
Data Sources
    * open DOI dataset via datahugger
    * STAC assets for satellite imagery 
    * Overture Maps for global admin boundaries, building footprints, and land cover
    * Irradiance data from Google’s Solar API and NREL’s National Solar Radiation Database
Data Ingestion
    * Hamilton dataflows for loading and processing raw data
    * raw sources standardized to (Geo)Parquet and loaded as dbt sources
Query
    * Transactional: PostgreSQL
        * Lakehouse Catalog
        * pgstac for querying STAC collections
        * pg_mooncake enables exporting and loading native pg tables as Iceberg tables
        * cloud via Neon serverless free tier
    * Analytical: DuckDB
        * for local processing and MotherDuck for cloud-scaling
Transport:
    * Apache Arrow for in-memory, zero-copy data exchange
Transform:
    * dbt for Python + SQL model development, data lineage, testing, and documentation
    * Ibis: Python dataframe API that compiles to multiple SQL backends
    * ELT dataflow pipeline built in python using dagworks's Hamilton DAGs
    * Arrays: 
        * Xarray, a library for manipulating and  operating on labeled multi-dimensional arrays
        * Tensorstore, a library for RW large ND-arrays
Parallelization
    * Local: Dask
    * scale Dask to cloud via Coiled
Data Products
    * datacubes of existing STAC imagery with PV locations
    * curated global PV dataset

# Hamilton + dbt Integration Best Practices

## Hamilton Dataflow Patterns
* Noun-based function naming (e.g., 'pv_h3_grid_cells' not 'pv_locations_to_h3')
* Dependency injection for configuration parameters
* Modular organization (<500 lines per file)
* Helper functions use single underscore prefix (_helper_function) to exclude from DAG visualizations
* Configurable variants of functions use "__suffix" with double underscore and @config.when decorator
* Functions with @config.when and __suffix MUST have identical signatures 
* Use config.when decorator for handling parallel vs sequential execution function variants
* AVOID creating file variants with suffixes (e.g., _simple, _v2) - import statements get forgotten, rely on version control instead
* Always verify import statements match the files being modified - check Builder.with_modules() calls before debugging
* Minimal exception handling and fallback approaches - delegate validation to dbt and prefer graceful failures over complex error handling
* GeoArrow-rs Python bindings for spatial operations with from_geopandas()/to_geopandas() and zero-copy Arrow conversion between nodes, WKB conversion as needed for DuckDB storage

## dbt Integration Patterns
* raw layer creates individual dataset tables preserving original schemas
* dbt uses raw layer tables as sources via {{ source('doi_pv_raw', 'table_name') }}
* dbt Python models execute Hamilton DAGs via configured Drivers and return Ibis dataframes

## DuckDB Configuration
* DuckDB has native Arrow support 
* Community extensions require 'from community' specification
* Essential extensions: spatial, h3, https, geography, ducklake
* Use DuckDB native hive partitioning by dates and countries for Parquet exports to object storage

## Spatial Data Handling
* H3 API v4+ with h3-py library for vectorized operations
* Prioritize geopandas sindex functions in spatial optimization and deduplication modules over duckdb spatial functions
* Use views (local) vs materialized views (prod) for Overture Maps data

## Cloud Configuration
* MotherDuck: md: prefix for cloud databases, token via environment variables
* Neon PostgreSQL: for multi-user ducklake + stac metadata, connection via environment variables
* Extension compatibility for cloud environments