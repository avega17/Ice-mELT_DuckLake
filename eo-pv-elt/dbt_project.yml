# dbt project configuration for EO PV data pipeline
# This file will be used by `dlt dbt generate` to create initial models

name: 'eo_pv_pipeline'
version: '0.0.2'
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: 'eo_pv_pipeline'

# dbt-cloud:
#     project-id: 70471823477636

# These configurations specify where dbt should look for different types of files.
# model-paths: ["models"]
# analysis-paths: ["analyses"]
test-paths: ["tests"]
# seed-paths: ["seeds"]
macro-paths: ["macros"]
# snapshot-paths: ["snapshots"]

target-path: "target"
clean-targets:
  - "target"
  - "dbt_packages"

# Environment variable setup for models

# Model configurations
models:
  eo_pv_pipeline:
    # Raw models - load data into DuckLake catalog
    raw:
      +materialized: view
      +database: eo_pv_lakehouse

    # Staging models - raw data with geopandas preprocessing (Python models)
    staging:
      +materialized: table
      +database: eo_pv_lakehouse

    # Prepared models - business logic transformations and data preparation
    prepared:
      +materialized: incremental
      +database: eo_pv_lakehouse

      # Overture Maps models should be views only to minimize storage
      prep_overture_countries:
        +materialized: table
      prep_country_h3_decomposition:
        +materialized: view

      # Large spatial models can use table materialization
      prep_pv_with_admin_boundaries:
        +materialized: table

    # Curated models - final analytical datasets
    # curated:
    #   +materialized: materialized view
    #   +schema: curated

  # Disable dbt_artifacts models temporarily to avoid missing table errors
  # dbt_artifacts:
  #   +enabled: false

# Seed configurations
seeds:
  eo_pv_pipeline:
    +schema: seeds

# tests:
#   +store_failures: true
#   +schema: test_failures

# Variables for the project
vars:
  # Date range for data processing
  start_date: '2015-01-01'
  end_date: '2025-12-31'

  # Coordinate reference systems
  default_crs: 'EPSG:4326'  # WGS84

  # Data quality thresholds
  min_geometry_area: 3  # minimum area in square meters
  max_geometry_area: 1000000  # maximum area in square meters

  # H3 spatial indexing settings
  h3_resolution: 12  # ~15,047.5 mÂ² hexagons for PV installations
  h3_country_resolution: 4  # ~1,770 kmÂ² hexagons for country decomposition

  # Spatial processing settings
  overlap_threshold: 0.5  # For duplicate detection
  buffer_distance_m: 150   # Buffer for spatial joins

  # DuckDB-specific settings
  use_native_geometry: true  # Use DuckDB spatial extension instead of WKT
  enable_spatial_index: true # Enable spatial indexing for performance


# Note: Sources are properly configured in models/sources.yml
# DuckDB-specific source configurations can be added here if needed

# DuckDB-specific configurations and environment setup
on-run-start:
  # Log target information for debugging
  - "{{ log('ðŸŽ¯ dbt target: ' ~ target.name, info=true) }}"
  # required for python models
  - "INSTALL arrow"
  - "LOAD arrow"
  - "CALL register_geoarrow_extensions()"
  - "INSTALL spatial"
  - "LOAD spatial"
  - "INSTALL ducklake"
  - "LOAD ducklake"
  - "INSTALL httpfs"
  - "LOAD httpfs"
  - "INSTALL h3 FROM community"
  - "LOAD h3"
  - "USE eo_pv_lakehouse;"
  # Configure S3 settings for R2 access (both dev and prod use R2)
  - "{% if target.name in ['dev', 'prod'] %}SET s3_access_key_id='{{ env_var('R2_ACCESS_KEY_ID') }}';{% endif %}"
  - "{% if target.name in ['dev', 'prod'] %}SET s3_secret_access_key='{{ env_var('R2_SECRET_KEY') }}';{% endif %}"
  - "{% if target.name in ['dev', 'prod'] %}SET s3_endpoint='{{ env_var('CLOUDFLARE_ACCOUNT_ID') }}.r2.cloudflarestorage.com';{% endif %}"
  - "{% if target.name in ['dev', 'prod'] %}SET s3_use_ssl=true;{% endif %}"
  - "{% if target.name in ['dev', 'prod'] %}SET s3_url_style='path';{% endif %}"
  # Note: geography extension temporarily commented out due to availability issues
  # - "INSTALL geography FROM community"
  # - "LOAD geography"
