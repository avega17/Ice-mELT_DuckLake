{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbc047b9",
   "metadata": {
    "id": "dbc047b9"
   },
   "source": [
    "# EDA of PV Datasets, Visualization, and Joining with Spatial Contexts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419c6b6",
   "metadata": {
    "id": "e419c6b6"
   },
   "source": [
    "### References:\n",
    "- [DuckLake Documentation](https://ducklake.select/docs/stable/)\n",
    "- [DuckLake with Ibis Python DataFrames](https://emilsadek.com/blog/ducklake-ibis/)\n",
    "- [A new data lakehouse with DuckLake and dbt](https://giacomo.coletto.io/blog/ducklake/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9egb5Sb9TdsD",
   "metadata": {
    "id": "9egb5Sb9TdsD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "SXahCyMWR2uA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXahCyMWR2uA",
    "outputId": "54275ba6-5c8f-430e-d4d9-f05228d209df"
   },
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    from google.colab import drive\n",
    "    from google.colab import userdata\n",
    "    import secrets\n",
    "\n",
    "    # fetch requirements from cloning repo because GDrive encodes as .gdoc reference and Windows keeps encoding as .docx\n",
    "    !git clone \"https://github.com/avega17/Ice-mELT_DuckLake.git\" \n",
    "    !ls -a\n",
    "    # note that segment-geospatial[samgeo2] takes quite a while to download all deps and build on colab 2-core cpu\n",
    "    !pip install -r Ice-mELT_DuckLake/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "776bafad",
   "metadata": {
    "id": "776bafad"
   },
   "outputs": [],
   "source": [
    "\n",
    "import ibis\n",
    "from ibis import _\n",
    "import ibis.selectors as s\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "# from huggingface_hub import HfFileSystem, login\n",
    "\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c79ae2",
   "metadata": {
    "id": "f3c79ae2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DuckLake catalog type: postgres\n",
      "  DATA_PATH: 's3://eo-pv-lakehouse/ducklake_data'\n"
     ]
    }
   ],
   "source": [
    "ibis.options.interactive = True\n",
    "ibis.options.graphviz_repr=True\n",
    "random.seed(24765131)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# assume we're using prod catalog, but default to local/dev if env var not set\n",
    "local_default = os.getenv('DUCKLAKE_CONNECTION_STRING_DEV')\n",
    "DUCKLAKE_CATALOG = os.getenv('DUCKLAKE_CONNECTION_STRING_PROD', local_default)\n",
    "DUCKLAKE_ATTACH = os.getenv(\"DUCKLAKE_ATTACH_PROD\")\n",
    "DUCKLAKE_NAME = os.getenv(\"DUCKLAKE_NAME\")\n",
    "DUCKLAKE_DATA_PATH = os.getenv(\"DUCKLAKE_DATA_PATH\")\n",
    "\n",
    "# pretty print our connection string info\n",
    "# TODO: comment out and remove output before commit\n",
    "print(f\"Using DuckLake catalog type: {DUCKLAKE_CATALOG.split(':')[1]}\" )\n",
    "catalog_creds = DUCKLAKE_CATALOG.split(':')[2].strip('()').split(' ')\n",
    "# skip DATA_PATH at end\n",
    "for cred in catalog_creds[:-2]:\n",
    "    key, val = cred.split('=')\n",
    "    # print(f\"  {key}: {val}\")\n",
    "print(f\"  DATA_PATH: {DUCKLAKE_CATALOG.split('DATA_PATH ')[1][:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563012e9",
   "metadata": {
    "id": "563012e9"
   },
   "source": [
    "### Connect to our data lake catalog with ibis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3546627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_duckdb.DuckDBPyConnection at 0x1089ec4f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# con.load_extension(\"ducklake\")\n",
    "attach_catalog_sql = f\"\"\"ATTACH IF NOT EXISTS '{DUCKLAKE_ATTACH}' AS {DUCKLAKE_NAME}\n",
    "    (DATA_PATH '{DUCKLAKE_DATA_PATH}');\n",
    "USE {DUCKLAKE_NAME};\n",
    "\"\"\"\n",
    "\n",
    "duckdb_config = {\n",
    "    'threads': 6,\n",
    "    'memory_limit': '12GB',\n",
    "    's3_access_key_id': os.getenv('R2_ACCESS_KEY_ID'),\n",
    "    's3_secret_access_key': os.getenv('R2_SECRET_KEY'),\n",
    "    's3_endpoint': os.getenv('R2_S3_ENDPOINT'),\n",
    "    's3_use_ssl': 'true',\n",
    "    's3_url_style': 'path'\n",
    "}\n",
    "\n",
    "extensions_query = \"\"\"\n",
    "    INSTALL httpfs;\n",
    "    LOAD httpfs;\n",
    "    INSTALL ducklake;\n",
    "    LOAD ducklake;\n",
    "    INSTALL spatial;\n",
    "    LOAD spatial;\n",
    "    INSTALL h3 FROM community;\n",
    "    LOAD h3;\n",
    "\"\"\"\n",
    "\n",
    "# first connect directly via duckdb to described views in DuckLake catalog\n",
    "con = duckdb.connect(database=':memory:', config=duckdb_config)\n",
    "con.execute(attach_catalog_sql)\n",
    "con.execute(extensions_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85936ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74048fe5ec6d49d98081a3254a390e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "905e0adc-a19e-4544-9702-d2633661ede4",
       "rows": [
        [
         "0",
         "pv_h3_cells"
        ],
        [
         "1",
         "pv_h3_grid"
        ],
        [
         "2",
         "raw_chn_med_res_pv_2024"
        ],
        [
         "3",
         "raw_global_harmonized_large_solar_farms_2020"
        ],
        [
         "4",
         "raw_global_pv_inventory_sent2_spot_2021"
        ],
        [
         "5",
         "raw_ind_pv_solar_farms_2022"
        ],
        [
         "6",
         "raw_uk_crowdsourced_pv_2020"
        ],
        [
         "7",
         "raw_usa_cali_usgs_pv_2016"
        ],
        [
         "8",
         "stg_chn_med_res_pv_2024"
        ],
        [
         "9",
         "stg_global_harmonized_large_solar_farms_2020"
        ],
        [
         "10",
         "stg_global_pv_inventory_sent2_spot_2021"
        ],
        [
         "11",
         "stg_ind_pv_solar_farms_2022"
        ],
        [
         "12",
         "stg_pv_consolidated"
        ],
        [
         "13",
         "stg_uk_crowdsourced_pv_2020"
        ],
        [
         "14",
         "stg_usa_cali_usgs_pv_2016"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 15
       }
      },
      "text/plain": [
       "[('pv_h3_cells',),\n",
       " ('pv_h3_grid',),\n",
       " ('raw_chn_med_res_pv_2024',),\n",
       " ('raw_global_harmonized_large_solar_farms_2020',),\n",
       " ('raw_global_pv_inventory_sent2_spot_2021',),\n",
       " ('raw_ind_pv_solar_farms_2022',),\n",
       " ('raw_uk_crowdsourced_pv_2020',),\n",
       " ('raw_usa_cali_usgs_pv_2016',),\n",
       " ('stg_chn_med_res_pv_2024',),\n",
       " ('stg_global_harmonized_large_solar_farms_2020',),\n",
       " ('stg_global_pv_inventory_sent2_spot_2021',),\n",
       " ('stg_ind_pv_solar_farms_2022',),\n",
       " ('stg_pv_consolidated',),\n",
       " ('stg_uk_crowdsourced_pv_2020',),\n",
       " ('stg_usa_cali_usgs_pv_2016',)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"show tables;\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e899e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CREATE VIEW raw_global_pv_inventory_sent2_spot_2021 AS WITH doi_manifest_raw '\n",
      " 'AS (SELECT * FROM '\n",
      " \"read_json_objects_auto('r2://eo-pv-lakehouse/pv_metadata/doi_manifest.json')), \"\n",
      " 'doi_manifest_expanded AS (SELECT je.\"key\" AS dataset_name, je.\"value\" AS '\n",
      " 'metadata_json FROM doi_manifest_raw AS dmr , json_each(dmr.\"json\") AS je), '\n",
      " 'dataset_metadata AS (SELECT dataset_name, json_extract_string(metadata_json, '\n",
      " \"'$.doi') AS doi, json_extract_string(metadata_json, '$.repo') AS repo, \"\n",
      " \"json_extract_string(metadata_json, '$.paper_doi') AS paper_doi, \"\n",
      " \"json_extract_string(metadata_json, '$.paper_title') AS paper_title FROM \"\n",
      " 'doi_manifest_expanded WHERE (dataset_name = '\n",
      " \"'global_pv_inventory_sent2_spot_2021'))SELECT * EXCLUDE (geometry), \"\n",
      " 'st_astext(st_geomfromwkb(geometry)) AS geometry_wkt, '\n",
      " 'st_aswkb(st_geomfromwkb(geometry)) AS geometry_wkb, dm.doi, dm.repo, '\n",
      " 'dm.paper_doi, dm.paper_title, CURRENT_TIMESTAMP AS dbt_loaded_at FROM '\n",
      " \"read_parquet('s3://eo-pv-lakehouse/geoparquet/raw_global_pv_inventory_sent2_spot_2021.parquet') \"\n",
      " ', dataset_metadata AS dm WHERE (st_isvalid(st_geomfromwkb(geometry)) = '\n",
      " \"CAST('t' AS BOOLEAN));\")\n"
     ]
    }
   ],
   "source": [
    "# see here for how to output view definition: https://duckdb.org/docs/stable/sql/statements/create_view\n",
    "view_query = con.execute(\"\"\"select sql FROM duckdb_views()\n",
    "        where view_name = 'raw_global_pv_inventory_sent2_spot_2021';\"\"\").fetchall()[0][0]\n",
    "pprint(view_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fea52ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Failed to find attached database \"catalog\"\n\nLINE 1: FROM ducklake_list_files('catalog', 'stg_uk_crowdsourced_pv_2020...\n             ^",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBinderException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# display the underlying data files that makes up one of the stg tables\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcon\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFROM ducklake_list_files(\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcatalog\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m, \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstg_uk_crowdsourced_pv_2020\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m);\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mBinderException\u001b[39m: Binder Error: Failed to find attached database \"catalog\"\n\nLINE 1: FROM ducklake_list_files('catalog', 'stg_uk_crowdsourced_pv_2020...\n             ^"
     ]
    }
   ],
   "source": [
    "# display the underlying data files that makes up one of the stg tables\n",
    "con.execute(\"FROM ducklake_list_files('catalog', 'stg_uk_crowdsourced_pv_2020');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05144b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# close duckdb connection so we can use ibis to connect\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bea8b5",
   "metadata": {
    "id": "12bea8b5"
   },
   "outputs": [],
   "source": [
    "# use in-memory/ephemeral db\n",
    "con = ibis.duckdb.connect(\n",
    "    extensions=[\"ducklake\", \"spatial\", \"h3\", \"httpfs\"],\n",
    "    **duckdb_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578360db",
   "metadata": {
    "id": "578360db"
   },
   "outputs": [],
   "source": [
    "\n",
    "con.raw_sql(attach_catalog_sql)\n",
    "# add community cache_httpfs extension; this causes an \"http_init already loaded\" error only when loading as part of ibis extensions arg\n",
    "con.raw_sql(\"INSTALL cache_httpfs FROM community; LOAD cache_httpfs;\")\n",
    "if 'google.colab' in str(get_ipython()): # only in colab, the extension doesn't seem to load with ibis's extensions arg\n",
    "    con.raw_sql(\"INSTALL h3 FROM community; LOAD h3;\")\n",
    "con.list_catalogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bad6a",
   "metadata": {
    "id": "b93bad6a"
   },
   "outputs": [],
   "source": [
    "con.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7663a706",
   "metadata": {
    "id": "7663a706"
   },
   "outputs": [],
   "source": [
    "stg_pv = con.table(\"stg_pv_consolidated\")\n",
    "# exclude the uk dataset as it seems to have no intersects and severely distorts our matching %\n",
    "# stg_pv = stg_pv.filter(_.dataset_name != 'uk_crowdsourced_pv_2020')\n",
    "\n",
    "@ibis.udf.scalar.builtin\n",
    "# signature returns GEOMETRY; use ibis geometry datatype\n",
    "def ST_GeomFromText(wkt: str) -> ibis.expr.datatypes.GeoSpatial:\n",
    "    '''Convert WKT to geometry'''\n",
    "stg_pv = stg_pv.mutate(geom=ST_GeomFromText(_.geometry))\n",
    "\n",
    "full_pv_dataset = stg_pv.to_pandas()\n",
    "full_pv_dataset =  gpd.GeoDataFrame(full_pv_dataset, geometry=full_pv_dataset['geometry'].apply(shapely.wkt.loads), crs='EPSG:4326')\n",
    "full_pv_dataset.describe()\n",
    "# save to geoparquet\n",
    "full_pv_dataset.to_parquet('full_pv_dataset.parquet', geometry_encoding='wkb', write_covering_bbox=True)\n",
    "\n",
    "\n",
    "\n",
    "# sample\n",
    "stg_pv.sample(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GkE11wmDIB9x",
   "metadata": {
    "id": "GkE11wmDIB9x"
   },
   "outputs": [],
   "source": [
    "stg_pv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ac6f7",
   "metadata": {
    "id": "213ac6f7"
   },
   "outputs": [],
   "source": [
    "from ibis import _\n",
    "\n",
    "# test h3 functionality: https://github.com/isaacbrodsky/h3-duckdb?tab=readme-ov-file#full-list-of-functions\n",
    "@ibis.udf.scalar.builtin\n",
    "def h3_latlng_to_cell_string(lat: float, lng: float, resolution: int) -> str:\n",
    "    '''Convert latitude/longitude coordinate to cell ID'''\n",
    "\n",
    "# and ibis udf that enables using backend's (duckdb) functions including extensions: https://ibis-project.org/reference/scalar-udfs#ibis.expr.operations.udf.scalar.builtin\n",
    "h3_test = stg_pv.sample(0.01).select(\"unified_id\", \"centroid_lat\", \"centroid_lon\").\\\n",
    "    mutate(h3_cell=h3_latlng_to_cell_string(_.centroid_lat, _.centroid_lon, 8)).head(10)\n",
    "display(h3_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6dc648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibis.expr.visualize import to_graph\n",
    "\n",
    "\n",
    "to_graph(con.table(\"stg_pv_consolidated\").sample(0.01).select(\"unified_id\", \"centroid_lat\", \"centroid_lon\").\\\n",
    "    mutate(h3_cell=h3_latlng_to_cell_string(_.centroid_lat, _.centroid_lon, 8)).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacb2cd",
   "metadata": {
    "id": "deacb2cd"
   },
   "outputs": [],
   "source": [
    "stg_pv.aggregate(by=[\"h3_index_8\"], pv_count=_.unified_id.count(), pv_area=_.area_m2.sum()).order_by(ibis.desc(\"pv_count\")).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1_header",
   "metadata": {
    "id": "step1_header"
   },
   "source": [
    "### Step 1: Convert PV Labels to GeoPandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1_convert_geopandas",
   "metadata": {
    "id": "step1_convert_geopandas"
   },
   "outputs": [],
   "source": [
    "# Fetched PV labels from DuckLake using ibis\n",
    "# Convert to pandas first; shuffle the rows (revise as dataset grows)\n",
    "pv_df = stg_pv.to_pandas().sample(frac=1)\n",
    "\n",
    "# Select a sample for MVP (e.g., 150-200 labels)\n",
    "# pv_sample = pv_df.sample(n=200, random_state=42)\n",
    "pv_sample = pv_df\n",
    "\n",
    "# Create GeoPandas dataframe and convert WKT geometry strings to shapely geometries\n",
    "pv_gdf = gpd.GeoDataFrame(pv_sample, geometry=pv_sample['geometry'].apply(shapely.wkt.loads), crs='EPSG:4326')\n",
    "\n",
    "print(f\"Loaded {len(pv_gdf)} PV labels into GeoPandas\")\n",
    "print(f\"Columns: {pv_gdf.columns.tolist()}\")\n",
    "pv_gdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many Point vs Polygon labels we have\n",
    "point_polygon_counts = pv_gdf['geometry'].geom_type.value_counts()\n",
    "print(\"Geometry Type Counts:\")\n",
    "print(point_polygon_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b657291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ice-mELT_ducklake (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
